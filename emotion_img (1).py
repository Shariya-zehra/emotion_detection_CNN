# -*- coding: utf-8 -*-
"""emotion_img.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19V8tTo3KlB99ZvU6cBn0CesrQTtklnZn
"""

import os
import cv2
import numpy as np

import matplotlib.pyplot as plt
import random
from sklearn.utils import shuffle
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.losses import CategoricalCrossentropy

import zipfile
import os
import shutil

from google.colab import files

uploaded = files.upload()

for filename in uploaded.keys():
    print('Uploaded file "{name}" with length {length} bytes'.format(
        name=filename, length=len(uploaded[filename])))

!kaggle datasets download -d ananthu017/emotion-detection-fer

from zipfile import ZipFile
file_name="/content/emotion-detection-fer.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done')

# Load and preprocess the images
def load_images_and_preprocess(subdir, class_label):
    images = []
    labels = []
    for filename in os.listdir(subdir):
        image_path = os.path.join(subdir, filename)
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale

        image = cv2.resize(image, (48, 48))  # Resize to 48*48
        image = np.expand_dims(image, axis=-1)  # Add channel dimension
        images.append(image)
        labels.append(class_label)
    return images, labels

train_dir = "/content/train"
test_dir= "/content/test"

desired_classes = ["angry", "happy", "sad", "neutral"]

X_train, y_train = [], []
X_test, y_test = [], []

for idx, emotion in enumerate(desired_classes):       # angry:0, happy:1, sad:2, neutral:3
  train_images, train_labels = load_images_and_preprocess(os.path.join(train_dir, emotion), idx)
  test_images, test_labels = load_images_and_preprocess(os.path.join(test_dir, emotion), idx)
  X_train.extend(train_images)
  y_train.extend(train_labels)
  X_test.extend(test_images)
  y_test.extend(test_labels)

print(len(X_train))
print(len(y_train))
print(len(X_test))
print(len(y_train))

# normalization
X_train = np.array(X_train) / 255.0
y_train = np.array(y_train)
X_test = np.array(X_test) / 255.0
y_test = np.array(y_test)

# Shuffling
X_train, y_train = shuffle(X_train, y_train, random_state=42)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

# One-hot encode labels
y_train = to_categorical(y_train, num_classes=len(desired_classes))
y_test = to_categorical(y_test, num_classes=len(desired_classes))

print(y_train.shape)
print(y_test.shape)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

datagen.fit(X_train)

# Build the model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),
    MaxPooling2D((2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Conv2D(256, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Flatten(),
    Dense(128, activation='relu'),

    Dense(4, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model

checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, mode='min')
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)


model.fit(datagen.flow(X_train, y_train, batch_size=32),
          epochs=30,
          validation_data=(X_test, y_test),
          callbacks=[checkpoint, reduce_lr, early_stopping])

# Evaluate
loss, accuracy = model.evaluate(X_test, y_test)
print('Test Loss:', loss)
print('Test accuracy:', accuracy)     #emotion detection

model.evaluate(X_train, y_train)

model.save('emotion_detection.h5')

predictions= model.predict(X_test)
class_labels=['Angry','Happy','Neutral','Sad']
n=random.randint(0, 5211)
image = X_test[n]

orig_labl = class_labels[np.argmax(y_test[n])]
pred_labl = class_labels[np.argmax(predictions[n])]
plt.imshow(image[:,:,0], cmap='gray')
plt.title("Original label is:"+orig_labl+" Predicted is: "+ pred_labl)
plt.show()